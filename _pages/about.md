---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
At Gatsby, my primary research interest is on learning theory such as kernel methods and deep learning theory. In particulars, I’m interested in establishing theoretical understandings between kernel methods and deep neural networks. Besides that, I’m also working on theoretical properties of various causal inference models.

Publication
======
-  [Optimal rates for regularized conditional mean embedding learning](https://proceedings.neurips.cc/paper_files/paper/2022/file/1c71cd4032da425409d8ada8727bad42-Paper-Conference.pdf)
Li Zhu\*, Dimitri Meunier\*, Mattes Mollenhauer, and Arthur Gretton. Advances in Neural Information Processing Systems 35 (2022): 4433-4445.(<span style="color:red">Oral Presentation</span>)

[Benign overfitting and noisy features.](https://www.tandfonline.com/doi/full/10.1080/01621459.2022.2093206)
Li Zhu, Weijie J. Su, and Dino Sejdinovic.  Journal of the American Statistical Association (2022): 1-13.

[Sharp Analysis of Random Fourier Features in Classification.](https://ojs.aaai.org/index.php/AAAI/article/view/20708)
Li, Zhu. In Proceedings of the AAAI Conference on Artificial Intelligence, vol. 36, no. 7, pp. 7444-7452. 2022.

[Kernel dependence regularizers and Gaussian processes with applications to algorithmic fairness.](](https://www.sciencedirect.com/science/article/pii/S0031320322004034))
Li Zhu, Adrián Pérez-Suay, Gustau Camps-Valls, and Dino Sejdinovic. Pattern Recognition 132 (2022): 108922.



